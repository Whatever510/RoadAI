{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Convolution2D, MaxPooling2D, Lambda, Reshape, Activation\n",
    "from tensorflow.keras.layers import Convolution2DTranspose, concatenate, Input, UpSampling2D, BatchNormalization, Add\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import ntpath\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Keras to use GPUs\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "# Check if GPU is available\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image resolution and the number of classes\n",
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "NUM_CLASSES = 11\n",
    "# Define the checkpoint name and the final model name\n",
    "CHECKPOINT_NAME = 'model_checkpoint.h5'\n",
    "MODEL_NAME = 'model.h5'\n",
    "\n",
    "MODEL_NAME = \"models/\" + MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the data\n",
    "datadir = 'data'\n",
    "# Specify the column names for the data\n",
    "cols = ['image_name', 'mask_name', 'binary_mask_name']\n",
    "# Read the data into a pandas dataframe\n",
    "data = pd.read_csv(os.path.join(datadir, 'labels.csv'), names=cols)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img_mask(datadir, df):\n",
    "    \"\"\"Load the images and mask path into memory\"\"\"\n",
    "    image_paths = []\n",
    "    mask_paths = []\n",
    "    for i in range(len(df)):\n",
    "        index_data = df.iloc[i]\n",
    "        image = index_data[0]\n",
    "        mask = index_data[2]\n",
    "        image_paths.append(os.path.join(datadir,image))\n",
    "        mask_paths.append(os.path.join(datadir,mask))\n",
    "    image_paths = np.asarray(image_paths)\n",
    "    mask_paths = np.asarray(mask_paths)\n",
    "    return image_paths, mask_paths\n",
    "\n",
    "image_paths, mask_paths = load_img_mask(datadir, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets. You can change the seed to generate a different training set.\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(image_paths, mask_paths, test_size=0.2, random_state=420)\n",
    "print('Training Samples: {}\\nValidation Samples: {}'.format(len(X_train), len(X_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 5 random images and masks to visualize the data\n",
    "fig, ax = plt.subplots(2, 5, figsize=(20, 8))\n",
    "for i in range(5):\n",
    "    ax[0, i].imshow(mpimg.imread(X_train[i]))\n",
    "    ax[0, i].set_title('Image: {}'.format(ntpath.basename(X_train[i])))\n",
    "    ax[1, i].imshow(mpimg.imread(y_train[i]))\n",
    "    ax[1, i].set_title('Mask: {}'.format(ntpath.basename(y_train[i])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_contrast(image):\n",
    "    \"\"\"Change the contrast of the image\"\"\"\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "    l_channel, a_channel, b_channel = cv2.split(lab)\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    l_channel = clahe.apply(l_channel)\n",
    "    limg = cv2.merge((l_channel, a_channel, b_channel))\n",
    "\n",
    "    image = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "    return image\n",
    "\n",
    "def img_random_brightness(image):\n",
    "    \"\"\"Change the brightness of the image\"\"\"\n",
    "    brightness = iaa.Multiply((0.8, 1.2))\n",
    "    image = brightness.augment_image(image)\n",
    "    # print(\"Brightness\", image.dtype)\n",
    "    return image\n",
    "\n",
    "def random_horizontal_flip(image, mask):\n",
    "    \"\"\"Flip the image and mask horizontally\"\"\"\n",
    "    horizontal_flip = iaa.Fliplr(1)\n",
    "    image = horizontal_flip.augment_image(image)\n",
    "    mask = horizontal_flip.augment_image(mask)\n",
    "    # print(\"Horizontal Flip\", image.dtype)\n",
    "    return image, mask\n",
    "\n",
    "def random_noise(image):\n",
    "    \"\"\"Add random 20 % noise to the image\"\"\"\n",
    "    #add 5% of noise to the image\n",
    "    noise = np.random.normal(0, 0.2, image.shape)\n",
    "    image = image + noise\n",
    "    # convert back to uint8\n",
    "    image = np.clip(image, 0, 255)\n",
    "    image = image.astype('uint8')\n",
    "    return image\n",
    "\n",
    "def crop_bottom(image, mask):\n",
    "    \"\"\"Crop the image and mask bottom\"\"\"\n",
    "    crop_value = np.random.randint(1, 200)\n",
    "    image = image[:-crop_value, :, :]\n",
    "    mask = mask[:-crop_value, :]\n",
    "    return image, mask\n",
    "\n",
    "def crop_top(image, mask):\n",
    "    \"\"\"Crop the image and mask top\"\"\"\n",
    "    crop_value = np.random.randint(1, 200)\n",
    "    image = image[crop_value:, :, :]\n",
    "    mask = mask[crop_value:, :]\n",
    "    return image, mask\n",
    "\n",
    "def change_saturation(image):\n",
    "    \"\"\"Change the saturation of the image\"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    image[:, :, 1] = image[:, :, 1] * np.random.uniform(0.7, 1.3)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_HSV2RGB)\n",
    "    return image\n",
    "\n",
    "def change_hue(image):\n",
    "    \"\"\"Change the hue of the image\"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    image[:, :, 0] = image[:, :, 0] + np.random.randint(-18, 18)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_HSV2RGB)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a all augmentation techniques on a random image\n",
    "def show_sample(image, mask):\n",
    "    image_contrast = change_contrast(image)\n",
    "    image_brightness = img_random_brightness(image)\n",
    "    image_noise = random_noise(image)\n",
    "    image_flip, mask_flip = random_horizontal_flip(image, mask)\n",
    "    image_crop_top, mask_crop_top = crop_top(image, mask)\n",
    "    image_crop_bottom, mask_crop_bottom = crop_bottom(image, mask)\n",
    "    image_saturation = change_saturation(image)\n",
    "    image_hue = change_hue(image)\n",
    "\n",
    "    fig, ax = plt.subplots(9, 2, figsize=(8, 20))\n",
    "    fig.tight_layout()\n",
    "    ax[0, 0].imshow(image)\n",
    "    ax[0, 0].set_title('Original Image')\n",
    "    ax[0, 1].imshow(mask)\n",
    "    ax[0, 1].set_title('Original Mask')\n",
    "    ax[1, 0].imshow(image_contrast)\n",
    "    ax[1, 0].set_title('Contrast Image')\n",
    "    ax[1, 1].imshow(mask)\n",
    "    ax[1, 1].set_title('Contrast Mask')\n",
    "    ax[2, 0].imshow(image_brightness)\n",
    "    ax[2, 0].set_title('Brightness Image')\n",
    "    ax[2, 1].imshow(mask)\n",
    "    ax[2, 1].set_title('Brightness Mask')\n",
    "    ax[3, 0].imshow(image_noise)\n",
    "    ax[3, 0].set_title('Noise Image')\n",
    "    ax[3, 1].imshow(mask)\n",
    "    ax[3, 1].set_title('Noise Mask')\n",
    "    ax[4, 0].imshow(image_flip)\n",
    "    ax[4, 0].set_title('Flipped Image')\n",
    "    ax[4, 1].imshow(mask_flip)\n",
    "    ax[4, 1].set_title('Flipped Mask')\n",
    "    ax[5, 0].imshow(image_crop_top)\n",
    "    ax[5, 0].set_title('Cropped Top Image')\n",
    "    ax[5, 1].imshow(mask_crop_top)\n",
    "    ax[5, 1].set_title('Cropped Top Mask')\n",
    "    ax[6, 0].imshow(image_crop_bottom)\n",
    "    ax[6, 0].set_title('Cropped Bottom Image')\n",
    "    ax[6, 1].imshow(mask_crop_bottom)\n",
    "    ax[6, 1].set_title('Cropped Bottom Mask')\n",
    "    ax[7, 0].imshow(image_saturation)\n",
    "    ax[7, 0].set_title('Saturation Image')\n",
    "    ax[7, 1].imshow(mask)\n",
    "    ax[7, 1].set_title('Saturation Mask')\n",
    "    ax[8, 0].imshow(image_hue)\n",
    "    ax[8, 0].set_title('Hue Image')\n",
    "    ax[8, 1].imshow(mask)\n",
    "    ax[8, 1].set_title('Hue Mask')\n",
    "    plt.show()\n",
    "\n",
    "image, mask = random.choice(list(zip(X_train, y_train)))\n",
    "# print(image, mask)\n",
    "image, mask = cv2.imread(image,cv2.IMREAD_COLOR), cv2.imread(mask,0)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# print(np.unique(mask))\n",
    "show_sample(image, mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly augment the images and masks\n",
    "def random_augment(image, mask):\n",
    "    path_img, path_mask = image, mask\n",
    "    image = cv2.imread(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    mask = cv2.imread(mask,0)\n",
    "    # Augment 75% of the images\n",
    "    should_augment = np.random.rand() < 0.75\n",
    "    \n",
    "    if should_augment:\n",
    "        if np.random.rand() < 0.5:\n",
    "            image, mask = random_horizontal_flip(image, mask)\n",
    "            if image is None or mask is None:\n",
    "                print(\"horizontal flip failed\")\n",
    "                print(path_img, path_mask)\n",
    "                \n",
    "        if np.random.rand() < 0.5:\n",
    "            image = random_noise(image)\n",
    "            if image is None or mask is None:\n",
    "                print(\"noise failed\")\n",
    "                print(path_img, path_mask)\n",
    "\n",
    "        if np.random.rand() < 0.5:\n",
    "            image, mask = crop_top(image, mask)\n",
    "            if image is None or mask is None:\n",
    "                print(\"crop top failed\")\n",
    "                print(path_img, path_mask)\n",
    "\n",
    "        if np.random.rand() < 0.5:\n",
    "            image = img_random_brightness(image)\n",
    "            if image is None or mask is None:\n",
    "                print(\"brightness failed\")\n",
    "                print(path_img, path_mask)\n",
    "\n",
    "        #if np.random.rand() < 0.5:\n",
    "            #image = change_brightness(image)\n",
    "            #if image is None or mask is None:\n",
    "                #print(\"brightness failed\")\n",
    "                #print(path_img, path_mask)\n",
    "\n",
    "        if np.random.rand() < 0.5:\n",
    "            image = change_hue(image)\n",
    "            if image is None or mask is None:\n",
    "                print(\"hue failed\")\n",
    "                print(path_img, path_mask)\n",
    "\n",
    "        if np.random.rand() < 0.5:\n",
    "            image = change_saturation(image)\n",
    "            if image is None or mask is None:\n",
    "                print(\"saturation failed\")\n",
    "                print(path_img, path_mask)\n",
    "\n",
    "        if np.random.rand() < 0.5:\n",
    "            image = change_contrast(image)\n",
    "            if image is None or mask is None:\n",
    "                print(\"contrast failed\")\n",
    "                print(path_img, path_mask)\n",
    "\n",
    "    # Crop the bottom in 50% of the images. This is required to avoid overfitting\n",
    "    # for the hood of the car.\n",
    "    if np.random.rand() < 0.50:\n",
    "        image, mask = crop_bottom(image, mask)\n",
    "        if image is None or mask is None:\n",
    "            print(\"crop bottom failed\")\n",
    "            print(path_img, path_mask)\n",
    "\n",
    "    if image is None or mask is None:\n",
    "        print(\"failed\")\n",
    "        print(path_img, path_mask)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_preprocess(image):\n",
    "    \"\"\"Preprocess the image\"\"\"\n",
    "    image = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    image = cv2.resize(image, (WIDTH, HEIGHT))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------------------------\n",
    "# The data generator is required to ease the memory load on the GPU. Only the images and masks required for training\n",
    "# step are loaded in memory. This happens dynamically when the generator is called.\n",
    "#----------------------------------------------------------------------------------------------------------------------\n",
    "def batch_generator(image_paths, mask_paths, batch_size, is_train=True):\n",
    "    \"\"\"A generator that returns images and masks.\"\"\"\n",
    "    while True:\n",
    "        batch_img = []\n",
    "        batch_mask = []\n",
    "        one_hot_mask = np.zeros((HEIGHT,WIDTH,NUM_CLASSES))\n",
    "        for i in range(batch_size):\n",
    "            random_index = random.randint(0, len(image_paths) - 1)\n",
    "            \n",
    "            if is_train:\n",
    "                img, mask = random_augment(image_paths[random_index], mask_paths[random_index])\n",
    "            else:\n",
    "                img = cv2.imread(image_paths[random_index])\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                mask = cv2.imread(mask_paths[random_index], 0)\n",
    "            try:\n",
    "                img = img_preprocess(img)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(image_paths[random_index])\n",
    "\n",
    "            mask = cv2.resize(mask, (WIDTH, HEIGHT), interpolation=cv2.INTER_NEAREST)\n",
    "            # One hot encoding of the mask\n",
    "            one_hot_mask = to_categorical(mask, num_classes=NUM_CLASSES)\n",
    "            batch_img.append(img)\n",
    "            batch_mask.append(one_hot_mask)\n",
    "        yield (np.asarray(batch_img), np.asarray(batch_mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Scaled down Unet model. Works ok with an image resolution of 160x120\"\"\"\n",
    "\n",
    "def unet_model(input_image, num_classes):\n",
    "\n",
    "    n0 = Lambda(lambda x: x/255 - 0.5)(input_image)\n",
    "\n",
    "    c1 = Convolution2D(8, (3, 3), activation='elu', padding='same')(n0)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Convolution2D(8, (3, 3), activation='elu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Convolution2D(16, (3, 3), activation='elu', padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Convolution2D(16, (3, 3), activation='elu', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Convolution2D(32, (3, 3), activation='elu', padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Convolution2D(32, (3, 3), activation='elu', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Convolution2D(64, (3, 3), activation='elu', padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Convolution2D(64, (3, 3), activation='elu', padding='same')(c4)\n",
    "\n",
    "    u5 = Convolution2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c4)\n",
    "    u5 = concatenate([u5, c3])\n",
    "    c5 = Convolution2D(32, (3, 3), activation='elu', padding='same')(u5)\n",
    "    c5 = Dropout(0.2)(c5)\n",
    "    c5 = Convolution2D(32, (3, 3), activation='elu', padding='same')(c5)\n",
    "\n",
    "    u6 = Convolution2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c2])\n",
    "    c6 = Convolution2D(16, (3, 3), activation='elu', padding='same')(u6)\n",
    "    c6 = Dropout(0.1)(c6)\n",
    "    c6 = Convolution2D(16, (3, 3), activation='elu', padding='same')(c6)\n",
    "\n",
    "    u7 = Convolution2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c1])\n",
    "    c7 = Convolution2D(8, (3, 3), activation='elu', padding='same')(u7)\n",
    "    c7 = Dropout(0.1)(c7)\n",
    "    c7 = Convolution2D(8, (3, 3), activation='elu', padding='same')(c7)\n",
    "\n",
    "    output = Convolution2D(num_classes, (1, 1), activation='softmax')(c7)\n",
    "\n",
    "    model = Model(inputs=[input_image], outputs=[output])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Unet with VGG16 encoder. Requires an image resolution of at least 224x224\"\"\"\n",
    "def vgg16_unet(input_image, num_classes):\n",
    "\n",
    "    n0 = Lambda(lambda x: x/255 - 0.5)(input_image)\n",
    "\n",
    "    c1 = Convolution2D(64, (3, 3), activation='relu', padding='same')(n0)\n",
    "    c1 = Convolution2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    c2 = Convolution2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Convolution2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "   \n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    c3 = Convolution2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = Convolution2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    c3 = Convolution2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    c4 = Convolution2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = Convolution2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    c4 = Convolution2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "\n",
    "    u5 = Convolution2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c4)\n",
    "    u5 = concatenate([u5, c3])\n",
    "    c5 = Convolution2D(256, (3, 3), activation='relu', padding='same')(u5)\n",
    "    c5 = Convolution2D(256, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    u6 = Convolution2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c2])\n",
    "    c6 = Convolution2D(128, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = Convolution2D(128, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = Convolution2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c1])\n",
    "    c7 = Convolution2D(64, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = Convolution2D(64, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    output = Convolution2D(num_classes, (1, 1), activation='softmax')(c7)\n",
    "\n",
    "    model = Model(inputs=[input_image], outputs=[output])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Input((HEIGHT, WIDTH, 3))\n",
    "model = vgg16_unet(input_image, NUM_CLASSES)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the callback to reduce the learning rate and stop training if the model does not improve after 3 epochs\n",
    "# Also initialize tensorboard for logging\n",
    "callbacks = [ModelCheckpoint(CHECKPOINT_NAME, monitor='val_loss', save_best_only=True),\n",
    "             EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True),\n",
    "             ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=4, verbose=1),\n",
    "             TensorBoard(log_dir='logs/', histogram_freq=5, write_graph=True, write_images=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model, this might take a while\n",
    "history = model.fit(batch_generator(X_train, y_train, batch_size=8, is_train=True),\n",
    "                    steps_per_epoch=100,\n",
    "                    epochs=40,\n",
    "                    validation_data=batch_generator(X_valid, y_valid, batch_size=8, is_train=False),\n",
    "                    validation_steps=60,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss function. Generally the validation loss should be less than the training loss\n",
    "# Both the training and validation loss should decrease over time\n",
    "# Traning and validation loss should be close to each other\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train', 'val'])\n",
    "plt.title('loss')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "model = load_model(MODEL_NAME)\n",
    "test_image = cv2.imread(\"psaf2_circle.png\")\n",
    "test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "test_image = cv2.resize(test_image, (WIDTH, HEIGHT))\n",
    "test_image = img_preprocess(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "pred = model.predict(test_image)\n",
    "pred = np.argmax(pred, axis=-1)\n",
    "pred = pred[0]\n",
    "pred = pred.astype(np.uint8)\n",
    "pred = cv2.resize(pred, (WIDTH, HEIGHT))\n",
    "print(np.unique(pred))\n",
    "# plot\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(test_image[0])\n",
    "ax[0].set_title('input image')\n",
    "ax[1].imshow(pred)\n",
    "ax[1].set_title('predicted mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(MODEL_NAME)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
